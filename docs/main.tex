\documentclass[a4paper]{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage[colorinlistoftodos]{todonotes}
\setlength{\parindent}{0cm}
\setlength{\parskip}{3mm plus1mm minus1mm}

\title{Evolutionary approach for solving the Rubik’s Cube}

\author{Wojciech Krzystek, Jan Stypka}

\date{\today}

\begin{document}
\maketitle

\begin{abstract}
The Rubik's cube is both a very popular toy and an interesting mathematical problem. Many algorithms have already been developed to provide an efficient way of calculating the solution, one of them being the family of evolutionary strategies. Herdy's algorithm is a very interesting member of this family, because of its simplicity and good performance. In this paper we try to present this approach and propose a few different enhancements to this algorithm. We also provide test results in order to illustrate the influence of our enhancements.
\end{abstract}

\section{Introduction}
\subsection{Problem}

The Rubik’s cube has been a subject of scientific research for many years since its invention by Erno Rubik. It is a discrete combinatorial optimisation problem with a solution space of \(4.3*10^{19}\)different configurations, which makes it a non trivial game.

The point of the game is to arrange properly a coloured cube, so that each side (further on called face) is composed of small squares (facelets) in a single colour. The player is able to rotate each face either clockwise or counterclockwise in order to descramble the cube.
Usually the best solution is the one made quickest, but some variations of the game reward shortest solutions in favor of the complicated ones.

\subsection{Cube structure}
The classic \(3^3\) cube consists of  26 pieces: 8 corner pieces, 12 edge pieces and 6 center pieces. As previously mentioned, each side of a cube will be called face and each face is composed of 9 single-coloured facelets. The name cubie is introduced to denote a physical object, which can have 1 (middle cubie), 2 (edge cubie) or 3 (corner) visible facelets. The classic Rubik’s cube is composed of 26 such cubies.

Each face can be rotated clockwise (CW) or counterclockwise (CCW) thereby changing the position of its facelets. However, the facelet at the centre cannot be moved by any possible and legal rotation, thus determining the colour of a solved face.

In fact the middle row can be physically rotated, but such move is equivalent to rotating two surrounding faces in the opposite direction, hence the mutual location of the facelets in the centres is pre-determined.

For every corner and edge piece it is of great importance to distinguish between its position and orientation: i.e. an edge can be in a right position (defined by the two adjacent center colours), but in the wrong orientation.

\subsection{Notation}
There are 12 possible rotations at each point of the game - a clockwise and counterclockwise for each of the faces. To distinguish between them we will use a standard notation consisting of \textit{F, R, U, B, L, D}  which stand for front, right, up, back, left, down clockwise turn respectively and \textit{Fi, Ri, Ui, Bi, Li, Di} accordingly for the counterclockwise rotations. Therefore a single move can be described as one letter and a sequence by a string such as \textit{FBiDURi}.

We can also distinguish half-turns (\textit{F2, R2, U2, B2, L2, D2}), which are achieved by two consecutive quarter-turns, but are often perceived as a single move.

To complete this description, we should also mention the colours. Various implementations may differ, but we will use a fairly standard configuration: i.e. \textit{F = white, R = red, U = blue, B = yellow, L = orange, D = green}. 

\section{Original Herdy's algorithm}
\subsection{Individual representation}
An individual is represented by a list of rotations and a cube state. This state is equivalent to the initial problem tackled with the rotations from the list. To store the cube 6 two-dimensional (3x3) matrices are used.

\subsection{Mutation}
Although mutations that change the color of only a single facelet would be suitable for evolutionary algorithm, since they introduce steady change of fitness, they would yield non-existent cube states.

We could thread any valid single move, such as, for instance, Fi, as a mutation, but it would introduce too abrupt changes in fitness value.

It just so happens that it’s more effective in terms of evolutionary algorithm to thread sequences of multiple moves, well-known to cube solvers, which interchange the position of just few, say, 2 cubies, or rotate a single cubie.

Unfortunately these sequences comprise of multiple moves, yielding very long solutions from scrambled for solved cube. We sacrifice the length of final solution for the simplicity of the algorithm.

The sequences (mutations) are presented in the table \ref{table:mutations}

\begin{table}[h]
\caption{Possible mutations}
\label{table:mutations}
\begin{tabular}{l|l|c}
\textbf{Mutation} & \textbf{Sequence} & \textbf{Length} \\
\hline
two edge flip CW & FRBLULiUBiRiFiLiUiLUi & 14 \\
\hline
two edge flip CCW & FiLiBiRiUiRUiBLFRURiU & 14 \\
\hline
two corner flip CW & LDiLiFiDiFUFiDFLDLiUi & 14 \\
\hline
two corner flip CCW & RiDRFDFiUiFDiFiRiDiRU & 14 \\
\hline
three edge swap CW & UF2UiRiDiLiF2LDR & 10 \\
\hline
three edge swap CCW & UiF2ULDRF2RiDiLi & 10 \\
\hline
two edge/corner swap CW & RiURUiRiUFRBiRBRFiR2 & 14 \\
\hline
two edge/corner swap CCW & LUiLiULUiFiLiBLiBiLiFL2 & 14 \\
\hline
three corner swap CW & FiUBUiFUBiUi & 8 \\
\hline
three corner swap CCW & FUiBiUFiUiBU & 8 \\
\hline
three inslice edge swap CW & RLiU2RiLF2 & 6 \\
\hline
three inslice edge swap CCW & LiRU2LRiF2 & 6 \\
\end{tabular}
\end{table}

This table does not include “mirrors” of the listed sequences.
To take mirrors into account when performing a new mutation:
\begin{enumerate}
\item The face of the cube for which the sequence will be applied is chosen randomly (6 possibilities).
\item Next, the orientation of the cube is chosen (4 possibilities, each achieved by rotating the whole cube 0, 1, 2, or 3 quarter-turns clockwise).
\end{enumerate}
Altogether we have $ 12\cdot6\cdot4 = 288 $ possible mutations

\subsection{Fitness calculation}
Three qualities $ q1 $, $ q2 $, $ q3 $ are introduced:
\begin{itemize}
\item $ q1 $ is increased by 1 for each facelet whose color differs from the center facelet on the same face
\item $ q2 $ is increased by 4 for each wrong positioned edge, orientation is not considered
\item $ q3 $ is increased by 6 for each wrong positioned corner, orientation is not considered
\end{itemize}
Fitness is a sum of those 3 components. The lower the fitness = the better. Solved cube has fitness 0.

\subsection{Selection}
The original Herdy’s algorithm does not enforce any type of selection, but suggests that a simple elitist selection should yield best results. This type of selection consists of two steps:

\begin{enumerate}
\item Sorting the whole population by the fitness value
\item Choosing  best individuals (with the smallest fitness)
\end{enumerate}

This kind of selection guarantees preserving the best individuals, but has a negative impact on population diversity.

\section{Implemented enhancements}
We propose two enhancements to the described algorithm. The first is a little more complex tournament selection described in the subchapter below and the second one is an attempt to shrink developed solutions, which can be very long.

For all enhancements appropriate tests have been performed with the results presented in a separate chapter.

\subsection{Tournament selection}
This kind of selection is slightly more complex than a basic elitist selection. It consists of three basic steps:
\begin{enumerate}
\item Divide population into random several equally large groups
\item Choose the best individual in each group in terms of fitness value
\item Create a new population composed of these chosen individuals
\end{enumerate}

The strategy guarantees preserving the best individual for the whole population, but the other (second best, third best etc.) champions may not be chosen for the subsequent generation.
However, this method in certain circumstances enables the selection of worse individuals, which improves population diversity and may have a positive impact on the convergence speed.
This selection strategy also does not involve sorting and may perform better in terms of pure calculation speed.

\subsection{Solution reduction}
Second enhancement is an attempt to reduce the length of possible solutions. After each mutation an additional sequence of rotations is concatenated to the previous result yielding very long solutions after certain number of generations.

The only possibility of reducing the length of solution without introducing significant chances to the algorithm itself,
is to use the fact that 2 consecutive rotations in the opposite directions, performed on the same cube wall can be reduced to no rotation.

e.g. a sequence of rotations: 'LLBBiLiUiUR' can be reduced to: 'LR', however this is an extreme case: results indicate that this strategy can reduce solution by no more than $5\%$.

\section{Tests}
\subsection{Parameters}
Basic parameters describing an evolutionary strategy are $(\mu, \lambda)$. The former defines the number of parents i.e. individuals selected from a population to give birth to another generation, while the latter parameter denotes offspring, that is the number of individuals generated from the previous population (parents).

During various tests run for the purpose of the experiment, we have empirically established a range of values, where the performance of the algorithm is the best. The program generally yielded better results for smaller values of $(\mu, \lambda)$, therefore we decided to take advantage of these observations to run our tests.

In order to ensure the lack of correlation between a specific combination of $(\mu, \lambda)$ and our results, we took  $(\mu, \lambda) = \{(x,y) : x \in \{10, 20, 50\} \wedge y \in \{100, 200, 500\}\}$. This also enables us to compare the influence of the parameters on the performance.

The same tests have been run twice on different computers, using different measuring techniques. This restricts our ability to draw conclusions from absolute numbers, however we are still able to compare relative values.


\subsection{Two possible approaches of measuring performance}
Tests have been carried out to determine the behaviour of the algorithm, depending on the chosen selection type and $(\mu, \lambda)$. Moreover two different measuring techniques were used:

Since a lot of executions of the algorithm tend to settle in a local optimum (most often with fitness ranging from $10$ to $30$)
and further computations (no matter how long) do not improve the final result, an upper bound of iterations number was introduced.
If the problem is not solved in this reasonable number of iterations, current execution of the algorithm is aborted and reattempted.
In order to overcome this obvious drawback and learn about its relation to the selection methods, we have chosen to implement two ways of time measurement:
\begin{itemize}
	\item	include \textit{invalid} runs: Since we need to make 10 successful runs, failed (stuck in a local optimum) runs are aborted,
			but time needed to perform this aborted run is added to the time of those 10 successful runs. It's ''fair'', since it matters if
			an algorithm can find a solution after 30 iterations, but more than a half of its runs end up as being aborted and the other algorithm
			is capable of finding a solution after 60 iterations, but only $10\%$ of its runs have to be terminated.
	\item measure only \textit{valid} runs: Measure only the time needed to make 10 successfull runs. In this method it doesn't matter how many times the algorithm had to be aborted.
\end{itemize}

Two methods have been compared using different machines, thus will be presented and discussed separately.

\subsubsection{Macromutation}

The problem of halting in a local optimum have also been tackled by the use of \textit{macromutation}. The basic idea of this method is to apply a sequence of deep mutations whenever the algorithm seems to stop on a certain fitness value before going to the selection phase. In our case a deep mutations is nothing more than a concatenated string of normal mutations, but exceptionally long. This set of mutations applied at once is able to change the fitness value more significantly and selection
is not performed prematurely.

This approach however did not give satisfying results. After observing no change in a population for 40 generations a random \textit{deep mutation} have been applied (sequence of 2-5 normal mutations), but no significant change in the algorithm behaviour was noted. Seldom the value finally dropped after a few generations, but this also happened without using macromutation with a similar frequency. Therefore we gave up using this method, because of lack of results.

\subsubsection{Only \textit{valid} runs}

\begin{table}[h]
\centering
\caption{Elitist selection}
\label{table:valid_elitist_tests}
\subfloat[Average time]{
  \begin{tabular}{c|c|c|c}
  & \textbf{100} & \textbf{200} & \textbf{500}\\
  \hline
  \textbf{10} & 21.95 & 20.31 & 34.50\\
  \hline
  \textbf{20} & 23.34 & 29.17 & 42.95\\
  \hline
  \textbf{50} & 43.06 & 37.74 & 52.83\\
  \end{tabular}
}
\subfloat[Generations]{
  \begin{tabular}{c|c|c|c}
  & \textbf{100} & \textbf{200} & \textbf{500}\\
  \hline
  \textbf{10} & 70.40 & 34.53 & 29.93\\
  \hline
  \textbf{20} & 75.47 & 49.07 & 31.13\\
  \hline
  \textbf{50} & 146.47 & 65.8 & 37.80\\
  \end{tabular}
}
\end{table}


\begin{table}[h]
\centering
\caption{Tournament selection}
\label{table:valid_tournament_tests}
\subfloat[Average time]{
  \begin{tabular}{c|c|c|c}
  & \textbf{100} & \textbf{200} & \textbf{500}\\
  \hline
  \textbf{10} & 28.13 & 37.95 & 75.85\\
  \hline
  \textbf{20} & 31.09 & 36.20 & 52.28\\
  \hline
  \textbf{50} & 27.16 & 41.85 & 65.70\\
  \end{tabular}
}
\subfloat[Generations]{
  \begin{tabular}{c|c|c|c}
  & \textbf{100} & \textbf{200} & \textbf{500}\\
  \hline
  \textbf{10} & 88.93 & 61.33 & 49.33\\
  \hline
  \textbf{20} & 102.4 & 60.27 & 36.73\\
  \hline
  \textbf{50} & 87.13 & 69.40 & 45.93\\
  \end{tabular}
}
\end{table}

The results clearly indicate a better performance for the elitist selection algorithm both in terms of time and the amount of generations. This numbers however include only the
\textit{valid} runs, discarding the attempts stuck and impossible for the algorithm to progress any further.

\subsubsection{Also \textit{invalid} runs}

The results including all executions are presented in tables \ref{table:invalid_elitist_tests} and \ref{table:invalid_tournament_tests}.

\begin{table}[h]
\centering
\caption{Elitist selection}
\label{table:invalid_elitist_tests}
\subfloat[Average time]{
  \begin{tabular}{c|c|c|c}
  & \textbf{100} & \textbf{200} & \textbf{500}\\
  \hline
  \textbf{10} & 53.48 & 75.61 & 383.12\\
  \hline
  \textbf{20} & 89.49 & 95.67 & 111.70\\
  \hline
  \textbf{50} & 52.54 & 38.41 & 124.30\\
  \end{tabular}
}
\subfloat[Generations]{
  \begin{tabular}{c|c|c|c}
  & \textbf{100} & \textbf{200} & \textbf{500}\\
  \hline
  \textbf{10} & 58.50 & 39.10 & 27.60\\
  \hline
  \textbf{20} & 98.70 & 57.30 & 35.90\\
  \hline
  \textbf{50} & 104.6 & 85.40 & 44.20\\
  \end{tabular}
}
\end{table}

\begin{table}[h]
\centering
\caption{Tournament selection}
\label{table:invalid_tournament_tests}
\subfloat[Average time]{
  \begin{tabular}{c|c|c|c}
  & \textbf{100} & \textbf{200} & \textbf{500}\\
  \hline
  \textbf{10} & 46.94 & 55.38 & 147.17\\
  \hline
  \textbf{20} & 42.88 & 86.63 & 176.63\\
  \hline
  \textbf{50} & 35.55 & 54.31 & 54.32\\
  \end{tabular}
}
\subfloat[Generations]{
  \begin{tabular}{c|c|c|c}
  & \textbf{100} & \textbf{200} & \textbf{500}\\
  \hline
  \textbf{10} & 97.50 & 76.00 & 56.10\\
  \hline
  \textbf{20} & 97.60 & 81.10 & 45.10\\
  \hline
  \textbf{50} & 85.90 & 68.70 & 40.00\\
  \end{tabular}
}
\end{table}

These numbers, on the other hand, show a better result of the tournament selection in terms of time, but favor elitist method regarding the number of generations needed to solve the cube. This might be expected, because the elitist method involves sorting and is therefore slightly slower, but the results differ widely from the previous tests.

This is probably due the difference in the measurement method and is more thoroughly discussed at the end of the paper. Elitist selection seems to be more vulnerable to the possibility of getting stuck and statistically is unable to solve a cube much more often. This is why it is slower when counting all executions, but shines when counting just the valid ones.

The tournament selection however does not perform better in solving the cube, but is less likely to get stuck during the computation and gives better results when counting all executions. The attempt to explain this phenomenon can be found in the final section of the article.

\subsection{Solution reduction}

As expected implemented reduction strategy introduced only a subtle improvement.\\
The lenght of the solution was proportional to the number of generations in a successful algorithm run,
hence elitist selection yielded shorter rotatation sequences.

\begin{table}[h]
\centering
\caption{Elitist selection}
\label{table:red_elitist_tests}
\subfloat[Average solution length]{
  \begin{tabular}{c|c|c|c}
  & \textbf{100} & \textbf{200} & \textbf{500}\\
  \hline
  \textbf{10} & 360.8 & 284.2 & 248\\
  \hline
  \textbf{20} & 417 & 351.6 & 290.6\\
  \hline
  \textbf{50} & 429 & 404.6 & 328.8\\
  \end{tabular}
}
\subfloat[Relative possible reduction]{
  \begin{tabular}{c|c|c|c}
  & \textbf{100} & \textbf{200} & \textbf{500}\\
  \hline
  \textbf{10} & 0.018 & 0.026 & 0.023	\\
  \hline
  \textbf{20} & 0.017 & 0.022 & 0.017 \\
  \hline
  \textbf{50} & 0.019 & 0.02 & 0.022\\
  \end{tabular}
}
\end{table}


\begin{table}[h]
\centering
\caption{Tournament selection}
\label{table:red_tournament_tests}
\subfloat[Average solution length]{
  \begin{tabular}{c|c|c|c}
  & \textbf{100} & \textbf{200} & \textbf{500}\\
  \hline
  \textbf{10} & 549.6 & 506.2 & 400\\
  \hline
  \textbf{20} & 601.2 & 499 & 351.8\\
  \hline
  \textbf{50} & 571.4 & 524.6 & 387.2\\
  \end{tabular}
}
\subfloat[Relative possible reduction]{
  \begin{tabular}{c|c|c|c}
  & \textbf{100} & \textbf{200} & \textbf{500}\\
  \hline
  \textbf{10} & 0.0167 & 0.02 & 0.0246	\\
  \hline
  \textbf{20} & 0.0149 & 0.02 & 0.02\\
  \hline
  \textbf{50} & 0.0197 & 0.0177 & 0.0204\\
  \end{tabular}
}
\end{table}

\section{Conclusions}

The purpose of this study was to implement and possibly enhance the original Herdy's algorithm for solving the Rubik's cube. Ideas proposed in this paper involve applying a tournament selection method and a module responsible for the reduction of possible solutions. The performance of proposed enhancements has been tested and the results have been presented.

Tests analyzing the performance of various methods of selection have been carried out on two machines and using two different measuring approaches. In the first case only the valid runs have been taken into account, while the second method measured all of the executions, including the ones which have timed out. Results indicated, that the tournament selection is much more immune to becoming halted by an unfortunate cube configuration, however it is outperformed in the case when only valid runs are considered. It is also slightly faster in terms of pure speed (time needed to increment the population, not the fitness convergence) due to its lack of sorting.

This phenomenon might be caused by the variety of population, which seems to be smothered by the elitist selection. By selecting only the narrow group of global champions in each generation, the population quickly becomes very homogenous and it is more and more difficult to create a solution varying significantly from the others. Tournament selection on the other hand enables occasional advancements of weaker individuals, which can outperform the rest of the population in future generations. This ability makes also the algorithm less vulnerable to becoming halted by an unfortunate cube configuration.

Further study of the topic might include examining the population diversity in each selection method or developing more advanced algorithms for the reduction of long solutions,
but this would entail changing original Herdy's algorithm to some other, designed specially to produce short solutions, such as, for instance Thistlethwaite algorithm.

\end{document}